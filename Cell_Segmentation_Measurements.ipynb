{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c2108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicspylibczi import CziFile\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import napari\n",
    "import pyclesperanto as cle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0524a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(input_image,tophat_radius):\n",
    "    input_gpu = cle.push(input_image)\n",
    "    #normalizing the image stack\n",
    "    equalized_intensities_stack = cle.create_like(input_gpu)\n",
    "    a_slice = cle.create([input_gpu.shape[-2], input_gpu.shape[-1]])\n",
    "    num_slices = input_gpu.shape[1]\n",
    "    num_channels = input_gpu.shape[0]\n",
    "    if num_channels == 1:\n",
    "        mean_intensity_stack = cle.mean_of_all_pixels(input_gpu)\n",
    "        corrected_slice = None\n",
    "        for z in range(0, num_slices):\n",
    "            # get a single slice out of the stack\n",
    "            cle.copy_slice(input_gpu, a_slice, z)\n",
    "            # measure its intensity\n",
    "            mean_intensity_slice = cle.mean_of_all_pixels(a_slice)\n",
    "            # correct the intensity\n",
    "            correction_factor = mean_intensity_slice/mean_intensity_stack\n",
    "            corrected_slice = cle.multiply_image_and_scalar(a_slice, corrected_slice, correction_factor)\n",
    "            # copy slice back in a stack\n",
    "            cle.copy_slice(corrected_slice, equalized_intensities_stack, z)\n",
    "    else:\n",
    "        for channel in range(num_channels):\n",
    "            mean_intensity_stack = cle.mean_of_all_pixels(input_gpu[channel,...])\n",
    "            corrected_slice = None\n",
    "            for z in range(0, num_slices):\n",
    "                # get a single slice out of the stack\n",
    "                cle.copy_slice(input_gpu[channel,...], a_slice, z)\n",
    "                # measure its intensity\n",
    "                mean_intensity_slice = cle.mean_of_all_pixels(a_slice)\n",
    "                # correct the intensity\n",
    "                correction_factor = mean_intensity_slice/mean_intensity_stack\n",
    "                corrected_slice = cle.multiply_image_and_scalar(a_slice, corrected_slice, correction_factor)\n",
    "                # copy slice back in a stack\n",
    "                cle.copy_slice(corrected_slice, equalized_intensities_stack[channel], z)\n",
    "    #background subtraction (increase the signal to noise ratio for improved segmentation results)\n",
    "    background_subtracted_top_hat = cle.top_hat_sphere(equalized_intensities_stack,radius_x=tophat_radius,radius_y=tophat_radius,radius_z=tophat_radius)\n",
    "    #pull data off gpu\n",
    "    input_pull = cle.pull(input_gpu)\n",
    "    background_subtracted_top_hat_pull = cle.pull(background_subtracted_top_hat)\n",
    "    equalized_intensities_stack_pull = cle.pull(equalized_intensities_stack)\n",
    "    return background_subtracted_top_hat_pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9faac4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OpenCL) NVIDIA RTX A4000 (OpenCL 3.0 CUDA)\n",
       "\tVendor:                      NVIDIA Corporation\n",
       "\tDriver Version:              573.24\n",
       "\tDevice Type:                 GPU\n",
       "\tCompute Units:               48\n",
       "\tGlobal Memory Size:          16375 MB\n",
       "\tLocal Memory Size:           0 MB\n",
       "\tMaximum Buffer Size:         4093 MB\n",
       "\tMax Clock Frequency:         1560 MHz\n",
       "\tImage Support:               Yes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cle.select_device(\"NVIDIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dce4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = sorted(glob(\"E:\\Fondufe-Mittendorf_Lab\\OIC-150_Images\\*.czi\"))\n",
    "czi_files = list(map(CziFile,file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b871b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = czi_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0d780cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BVSTCZYX'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f190c737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 3, 1, 4, 24, 1012, 1012)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80e5a649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_image in module aicspylibczi.CziFile:\n",
      "\n",
      "read_image(self, **kwargs)\n",
      "    Read the subblocks in the CZI file and for any subblocks that match all the constraints in kwargs return\n",
      "    that data. This allows you to select channels/scenes/time-points/Z-slices etc. Note if passed a BGR image\n",
      "    then the dims of the object will returned by this function and the implicit BGR will be expanded into an\n",
      "    A dimension. A is samples per pixel and will only be present for BGR images. This is logically more consistent\n",
      "    than mixing the samples into the channels as was done before aicspylibczi-3.0.0.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    **kwargs\n",
      "        The keywords below allow you to specify the dimensions that you wish to match. If you\n",
      "        under-specify the constraints you can easily end up with a massive image stack.\n",
      "             Z = 1   # The Z-dimension.\n",
      "             C = 2   # The C-dimension (\"channel\").\n",
      "             T = 3   # The T-dimension (\"time\").\n",
      "             R = 4   # The R-dimension (\"rotation\").\n",
      "             S = 5   # The S-dimension (\"scene\").\n",
      "             I = 6   # The I-dimension (\"illumination\").\n",
      "             H = 7   # The H-dimension (\"phase\").\n",
      "             V = 8   # The V-dimension (\"view\").\n",
      "             M = 10  # The M_index, this is only valid for Mosaic files!\n",
      "        Specify the number of cores to use for multithreading with cores.\n",
      "            cores = 3 # use 3 cores for threaded reading of the image.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    (numpy.ndarray, [Dimension, Size])\n",
      "        a tuple of (numpy.ndarray, a list of (Dimension, size)) the second element of the tuple is to make\n",
      "        sure the numpy.ndarray is interpretable. An example of the list is\n",
      "        [('S', 1), ('T', 1), ('C', 2), ('Z', 25), ('Y', 1024), ('X', 1024)]\n",
      "        so if you probed the numpy.ndarray with .shape you would get (1, 1, 2, 25, 1024, 1024).\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The M Dimension is a representation of the m_index used inside libCZI. Unfortunately this can be sparsely\n",
      "    packed for a given selection which causes problems when indexing memory. Consequently the M Dimension may\n",
      "    not match the m_index that is being used in libCZI or displayed in Zeiss' Zen software.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(CziFile.read_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f648c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = [test_img.read_image(S=i)[0] for i in range(test_img.size[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09414d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.squeeze(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "293a72d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 24, 1012, 1012)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = img[0]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef08aaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dimension value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gpu_in \u001b[38;5;241m=\u001b[39m \u001b[43mcle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\CellPoseCLE-env\\lib\\site-packages\\pyclesperanto\\_memory.py:124\u001b[0m, in \u001b[0;36mpush\u001b[1;34m(array, dtype, mtype, device)\u001b[0m\n\u001b[0;32m    121\u001b[0m     array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(array)\n\u001b[0;32m    123\u001b[0m dtype \u001b[38;5;241m=\u001b[39m dtype \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;28;01melse\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\CellPoseCLE-env\\lib\\site-packages\\pyclesperanto\\_array.py:73\u001b[0m, in \u001b[0;36mset\u001b[1;34m(self, array, origin, region)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue size mismatch the targeted region: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mprod(region)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(np\u001b[38;5;241m.\u001b[39msqueeze(region))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m region \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m array\u001b[38;5;241m.\u001b[39msize:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m---> 73\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue size mismatch the targeted region: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m     )\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write(_prepare_array(array), origin, region)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid dimension value"
     ]
    }
   ],
   "source": [
    "gpu_in = cle.push(test) #cle does not take multichannel images. Need to recreate the background norm function with Skimage and NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7addb2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellPose_CLE_Skan",
   "language": "python",
   "name": "cellpose_cle_skan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
